{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "zMxESKUdfQkT",
        "outputId": "54793788-f3c8-4fad-a4e3-2f04a280464f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========== Q1: SMS SPAM AdaBoost ===========\n",
            "Dataset Loaded — Spam / Ham Counts: [4825  747]\n",
            "Iteration 1 | train=0.8833 | test=0.8960 | error=0.1167 | alpha=1.0122\n",
            "Iteration 2 | train=0.8833 | test=0.8960 | error=0.2582 | alpha=0.5278\n",
            "Iteration 3 | train=0.8833 | test=0.8960 | error=0.2981 | alpha=0.4281\n",
            "Iteration 4 | train=0.9150 | test=0.9256 | error=0.3796 | alpha=0.2457\n",
            "Iteration 5 | train=0.8948 | test=0.9058 | error=0.3861 | alpha=0.2319\n",
            "Iteration 6 | train=0.9266 | test=0.9291 | error=0.3907 | alpha=0.2221\n",
            "Iteration 7 | train=0.9138 | test=0.9193 | error=0.3910 | alpha=0.2216\n",
            "Iteration 8 | train=0.9289 | test=0.9300 | error=0.3949 | alpha=0.2133\n",
            "Iteration 9 | train=0.9190 | test=0.9229 | error=0.3749 | alpha=0.2555\n",
            "Iteration 10 | train=0.9145 | test=0.9202 | error=0.4577 | alpha=0.0848\n",
            "Iteration 11 | train=0.9338 | test=0.9354 | error=0.3902 | alpha=0.2233\n",
            "Iteration 12 | train=0.9264 | test=0.9265 | error=0.4175 | alpha=0.1665\n",
            "Iteration 13 | train=0.9282 | test=0.9309 | error=0.4557 | alpha=0.0889\n",
            "Iteration 14 | train=0.9230 | test=0.9283 | error=0.4356 | alpha=0.1296\n",
            "Iteration 15 | train=0.9293 | test=0.9318 | error=0.4472 | alpha=0.1060\n",
            "\n",
            "Manual AdaBoost Final Accuracy: 0.9318385650224216\n",
            "Confusion Matrix:\n",
            " [[953  13]\n",
            " [ 63  86]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3031572312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Sklearn AdaBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m adb = AdaBoostClassifier(\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# ADABOOST FULL ASSIGNMENT (Q1 + Q2 + Q3)\n",
        "# All datasets auto-download — NO upload needed\n",
        "# ===============================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import requests, re, string\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ====================================================\n",
        "def clean_text(s):\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"http\\S+|www\\S+\", \"\", s)\n",
        "    s = s.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    return s\n",
        "\n",
        "\n",
        "def manual_adaboost(X_train, y_train, X_test, y_test, T=20):\n",
        "    n = len(y_train)\n",
        "    w = np.ones(n) / n\n",
        "    y_train2 = np.where(y_train == 1, 1, -1)\n",
        "    y_test2 = np.where(y_test == 1, 1, -1)\n",
        "\n",
        "    train_score_list = []\n",
        "    test_score_list = []\n",
        "    alpha_list = []\n",
        "    error_list = []\n",
        "\n",
        "    F_train = np.zeros(n)\n",
        "    F_test = np.zeros(len(y_test))\n",
        "\n",
        "    for t in range(1, T + 1):\n",
        "        stump = DecisionTreeClassifier(max_depth=1)\n",
        "        stump.fit(X_train, y_train, sample_weight=w)\n",
        "\n",
        "        pred_train = stump.predict(X_train)\n",
        "        pred_train2 = np.where(pred_train == 1, 1, -1)\n",
        "\n",
        "        err = np.sum(w[pred_train2 != y_train2])\n",
        "        err = max(min(err, 0.999), 1e-10)\n",
        "\n",
        "        alpha = 0.5 * np.log((1 - err) / err)\n",
        "\n",
        "        w *= np.exp(-alpha * y_train2 * pred_train2)\n",
        "        w /= np.sum(w)\n",
        "\n",
        "        pred_test = stump.predict(X_test)\n",
        "        pred_test2 = np.where(pred_test == 1, 1, -1)\n",
        "\n",
        "        F_train += alpha * pred_train2\n",
        "        F_test += alpha * pred_test2\n",
        "\n",
        "        train_acc = accuracy_score(y_train, (F_train >= 0).astype(int))\n",
        "        test_acc = accuracy_score(y_test, (F_test >= 0).astype(int))\n",
        "\n",
        "        train_score_list.append(train_acc)\n",
        "        test_score_list.append(test_acc)\n",
        "        alpha_list.append(alpha)\n",
        "        error_list.append(err)\n",
        "\n",
        "        print(f\"Iteration {t} | train={train_acc:.4f} | test={test_acc:.4f} | error={err:.4f} | alpha={alpha:.4f}\")\n",
        "\n",
        "    final_pred = (F_test >= 0).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"train_scores\": train_score_list,\n",
        "        \"test_scores\": test_score_list,\n",
        "        \"alphas\": alpha_list,\n",
        "        \"errors\": error_list,\n",
        "        \"final_pred\": final_pred,\n",
        "    }\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Q1 — SMS SPAM (AdaBoost Manual + Sklearn)\n",
        "# ====================================================\n",
        "\n",
        "print(\"\\n=========== Q1: SMS SPAM AdaBoost ===========\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df = pd.read_csv(url, sep=\"\\t\", names=[\"label\", \"text\"])\n",
        "df[\"label_bin\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "df[\"clean\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "vec = TfidfVectorizer(max_features=4000)\n",
        "X = vec.fit_transform(df[\"clean\"])\n",
        "y = df[\"label_bin\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.toarray(), y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Dataset Loaded — Spam / Ham Counts:\", np.bincount(y))\n",
        "\n",
        "\n",
        "# Manual AdaBoost\n",
        "manual_result = manual_adaboost(X_train, y_train, X_test, y_test, T=15)\n",
        "\n",
        "print(\"\\nManual AdaBoost Final Accuracy:\", accuracy_score(y_test, manual_result[\"final_pred\"]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, manual_result[\"final_pred\"]))\n",
        "\n",
        "\n",
        "# Sklearn AdaBoost\n",
        "adb = AdaBoostClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.6,\n",
        ")\n",
        "\n",
        "adb.fit(X_train, y_train)\n",
        "print(\"\\nSklearn AdaBoost Accuracy:\", adb.score(X_test, y_test))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, adb.predict(X_test)))\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Q2 — HEART DISEASE AdaBoost\n",
        "# ====================================================\n",
        "\n",
        "print(\"\\n=========== Q2: HEART DISEASE AdaBoost ===========\")\n",
        "\n",
        "heart_url = \"https://raw.githubusercontent.com/plotly/datasets/master/heart.csv\"\n",
        "heart = pd.read_csv(heart_url)\n",
        "\n",
        "y = heart[\"target\"].values\n",
        "X = heart.drop(columns=[\"target\"])\n",
        "\n",
        "X = pd.get_dummies(X)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Baseline stump\n",
        "stump = DecisionTreeClassifier(max_depth=1)\n",
        "stump.fit(X_train, y_train)\n",
        "print(\"Stump Test Accuracy:\", stump.score(X_test, y_test))\n",
        "\n",
        "\n",
        "# Grid Search\n",
        "best_acc = -1\n",
        "best_model = None\n",
        "for n in [10, 25, 50, 100]:\n",
        "    for lr in [0.1, 0.5, 1.0]:\n",
        "        model = AdaBoostClassifier(\n",
        "            base_estimator=DecisionTreeClassifier(max_depth=1),\n",
        "            n_estimators=n,\n",
        "            learning_rate=lr,\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_test, y_test)\n",
        "        print(f\"n={n}, lr={lr} → acc={acc:.4f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_model = model\n",
        "\n",
        "print(\"\\nBest AdaBoost Model Accuracy:\", best_acc)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, best_model.predict(X_test)))\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Q3 — WISDM ACTIVITY AdaBoost\n",
        "# ====================================================\n",
        "\n",
        "print(\"\\n=========== Q3: WISDM AdaBoost ===========\")\n",
        "\n",
        "wisdm_url = (\n",
        "    \"https://raw.githubusercontent.com/ankitaggarwal011/Activity-Recognition-WISDM/master/WISDM_ar_v1.1_raw.txt\"\n",
        ")\n",
        "df = pd.read_csv(wisdm_url, header=None, names=[\"raw\"], engine=\"python\")\n",
        "\n",
        "def parse_row(row):\n",
        "    try:\n",
        "        parts = row.split(\",\")\n",
        "        act = parts[1].strip()\n",
        "        x, y, z = float(parts[3]), float(parts[4]), float(parts[5])\n",
        "        return act, x, y, z\n",
        "    except:\n",
        "        return None, None, None, None\n",
        "\n",
        "parsed = df[\"raw\"].apply(parse_row)\n",
        "parsed = pd.DataFrame(parsed.tolist(), columns=[\"act\", \"x\", \"y\", \"z\"])\n",
        "parsed = parsed.dropna()\n",
        "\n",
        "parsed[\"label\"] = parsed[\"act\"].apply(lambda a: 1 if \"Jog\" in a or \"Up\" in a else 0)\n",
        "\n",
        "X = parsed[[\"x\", \"y\", \"z\"]].values\n",
        "y = parsed[\"label\"].values\n",
        "\n",
        "# downsample (dataset is HUGE)\n",
        "idx = np.random.choice(len(X), 30000, replace=False)\n",
        "X, y = X[idx], y[idx]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Manual AdaBoost\n",
        "wisdm_res = manual_adaboost(X_train, y_train, X_test, y_test, T=20)\n",
        "\n",
        "print(\"\\nManual AdaBoost WISDM Accuracy:\", accuracy_score(y_test, wisdm_res[\"final_pred\"]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, wisdm_res[\"final_pred\"]))\n",
        "\n",
        "\n",
        "# Sklearn AdaBoost\n",
        "adb2 = AdaBoostClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=100,\n",
        "    learning_rate=1.0,\n",
        ")\n",
        "\n",
        "adb2.fit(X_train, y_train)\n",
        "print(\"\\nSklearn AdaBoost WISDM Accuracy:\", adb2.score(X_test, y_test))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, adb2.predict(X_test)))\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "print(\"\\n============= ALL QUESTIONS DONE SUCCESSFULLY =============\")\n"
      ]
    }
  ]
}